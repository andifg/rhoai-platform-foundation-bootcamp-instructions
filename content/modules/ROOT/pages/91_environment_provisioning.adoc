= **Provisioning a GPU Environment with NVIDIA A100**
:icons: font

== **Patch for MachineSet Labels and Taints**
* To activate the specific slicing configuration you defined, you must **apply a necessary label** (e.g., `nvidia.com/device-plugin.config: tesla-t4`) to your MachineSet that provides the GPU nodes.

[source,yaml]
----
apiVersion: machine.openshift.io/v1beta1
kind: MachineSet
metadata:
  # ... other metadata
spec:
  # ... other spec
  template:
    spec:
      metadata:
        labels:
          nvidia.com/device-plugin.config: tesla-t4 # A100 is needed here
----

* If you also want to **taint your GPU nodes to restrict access** or ensure only GPU-requiring Pods land on them, you should **define these taints declaratively in your MachineSet**. This avoids manual ``oc adm taint`` commands.

[source,yaml]
----
apiVersion: machine.openshift.io/v1beta1
kind: MachineSet
metadata:
  # ... other metadata
spec:
  # ... other spec
  template:
    spec:
      # ... other template spec
      taints:
        - key: restrictedaccess
          value: "yes"
          effect: NoSchedule
----
* Then, you must **apply the relevant toleration to the NVIDIA GPU Operator's `ClusterPolicy`** within the ``nvidia-gpu-operator`` namespace. This allows the operator to deploy its tooling on tainted nodes.

[source,yaml]
----
apiVersion: nvidia.com/v1
kind: ClusterPolicy
metadata:
  # ... other metadata
  name: gpu-cluster-policy
  namespace: nvidia-gpu-operator
spec:
  daemonsets:
    tolerations:
      - effect: NoSchedule
        key: restrictedaccess
        operator: Exists
----

* **Note**: The ``nvidia.com/gpu``` taint is a standard taint for which the NVIDIA Operator has a built-in toleration, so you don't need to explicitly add it to the `ClusterPolicy`. Components from Open Data Hub (ODH) or Red Hat OpenShift AI (RHOAI) that request GPUs will also have this toleration in place.

== **Autoscaler Configuration for GPU Nodes**

As GPUs are expensive, they are good candidates for autoscaling.

* To help the Autoscaler understand the GPU type and work properly, you have to **set a specific label to the MachineSet**. For example, ``cluster-api/accelerator: Tesla-T4-SHARED``.

[source,yaml]
----
apiVersion: machine.openshift.io/v1beta1
kind: MachineSet
metadata:
  # ... other metadata
spec:
  # ... other spec
  template:
    spec:
      metadata:
        labels:
          cluster-api/accelerator: Tesla-T4-SHARED
----
*   To allow scaling to zero for GPU MachineSets, an annotation `machine.openshift.io/GPU: "1"` may need to be set manually on the MachineSet if not present after the first scale up.
*   For environments with multiple Availability Zones (AZs), add `topology.kubernetes.io/zone` and `topology.ebs.csi.aws.com/zone` labels to the MachineSet template's node labels to ensure the Autoscaler simulates node provisioning in the correct AZ.