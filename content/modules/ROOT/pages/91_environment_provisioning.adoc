= **Provisioning a GPU Environment with NVIDIA A30 GPUs**
:icons: font

== **Install the AWS Enviroment**
* Follow the instructions in the xref:05_environment_provisioning.adoc[RHOAI Foundation Bootcamp: Provisioning a GPU Environment] to set up your AWS environment.



== **Clone the RHOAI GitHub Repository**
* Clone the RHOAI GitHub repository to your local machine: 

[.console-input]
[source,bash]
----
git clone https://github.com/shebistar/ai-accelerator.git # TODO: Change to official repo when available
cd ai-accelerator
----

== **Temporary Step:** change to the feature/gpu-as-a-service branch
* Checkout the `feature/gpu-as-a-service` branch to access the necessary configurations for GPU support.

[.console-input]
[source,bash]
----
git checkout feature/gpu-as-a-service
----

== **Execute the bootstrap script**
* Run the bootstrap script to set up the environment. This script will handle the installation of necessary components and configurations.

Follow the instructions provided in the xref:07_installation.adoc#_bootstrap_the_gpu_cluster[Bootstrap the GPU Cluster] document to complete the installation process.

And select the option with rhoai-satable-2.22-aws-gpu-time-sliced

[.console-input]
[source,bash]
----
./bootstrap.sh
----


[.bordershadow]
image::select-overlay.png[]



* If the script is asking you to update the branch to match your working branch, please do so, selecting option 1 in both prompts.

[.bordershadow]
image::update_branch.png[]

Now you can browse to the OpenShift console and see that the cluster is up and running. Go to Compute --> Nodes to see the nodes.

[.bordershadow]
image::gpunodes.png[]


== **Enable Monitoring for GPU Nodes**

* To enable monitoring for GPU nodes, you need to **add a specific configMap to the `openshift-monitoring` namespace**. This configMap will instruct the monitoring stack to scrape GPU metrics from the nodes.

Create a folder named `gpu-as-a-service/nvidia-dcgm-exporter-dashboard`

[.console-input]
[source,bash]
----
mkdir -p gpu-as-a-service/nvidia-dcgm-exporter-dashboard
cd gpu-as-a-service/nvidia-dcgm-exporter-dashboard
----

Inside the folder create a file named `kustomization.yaml` with the following content:


[.console-input]
[source,yaml]
----
apiVersion: kustomize.config.k8s.io/v1alpha1
kind: Component

generatorOptions:
  labels:
    console.openshift.io/dashboard: "true"
    # optional label to enable visibilty in developer perspective
    console.openshift.io/odc-dashboard: "true"
  disableNameSuffixHash: true

configMapGenerator:
  - name: nvidia-dcgm-exporter-dashboard
    namespace: openshift-config-managed
    files:
      - https://github.com/NVIDIA/dcgm-exporter/raw/main/grafana/dcgm-exporter-dashboard.json
----


* Apply the configMap to the `openshift-monitoring` namespace using `oc`:

[.console-input]
[source,bash]
----
oc apply -k .
----

It should return something like:

[source,bash]
----
configmap/nvidia-dcgm-exporter-dashboard created
----

* After applying the configMap, you should see a new dashboard named "NVIDIA DCGM Exporter Dashboard" in the OpenShift Monitoring section (Observe --> Dashboards --> NVIDIA DCGM Exporter Dashboard).

[.bordershadow]
image::nvidia-dcgm-dashboard.png[]


== Configure the console plugin for GPU Monitoring

* Follow the instructions on the following page: https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/openshift/enable-gpu-op-dashboard.html#enable-the-gpu-operator-dashboard[Enable the NVIDIA GPU Operator usage information,window=_blank]

